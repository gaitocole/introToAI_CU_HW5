{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histopathologic Cancer Detection\n",
    "    - Site Location: https://www.kaggle.com/competitions/histopathologic-cancer-detection/overview\n",
    "##### Student - Cole Gaito\n",
    "##### University of Colorado - AI Course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "#Basic Hello World program\n",
    "#Tested on Python 3.12.4\n",
    "#Ensure that the Kernel is operational\n",
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/4.2.3/libexec/bin/python\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(sys\u001b[38;5;241m.\u001b[39mexecutable)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__version__\u001b[49m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython executable:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sys\u001b[38;5;241m.\u001b[39mexecutable)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sys\u001b[38;5;241m.\u001b[39mversion)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "#Check if Numpy is available\n",
    "import sys\n",
    "print(sys.executable)\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "print(\"Python executable:\", sys.executable)\n",
    "print(\"Python version:\", sys.version)\n",
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1649797387.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    pip !list\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#pip install numpy --upgrade\n",
    "pip !list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the various objects of utilized for Pytorch and our ML Algorithims lets start building.  We will begin by creating a subclass of the Dataset called CancerDataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Directory Locations to ease use later.\n",
    "csv_file = \"train_lables.csv\"\n",
    "root_dir = \"../train/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CancerDataset(Dataset):\n",
    "    #Arguements: csv_file - location of the csv file in a string format\n",
    "    #            root_dir - directory with all the images in a string format\n",
    "    #            transform - callable and optional toggle for a sample set\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.labels_df = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_name = os.path.join(self.root_dir, self.labels_df.iloc[idx, 0] + '.tif')\n",
    "        image = Image.open(img_name)\n",
    "        label = self.labels_df.iloc[idx, 1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((96, 96)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CancerDataset(csv_file='train_labels.csv', root_dir='train', transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(images.shape)  # Should print (batch_size, 3, 96, 96)\n",
    "    print(labels)        # Corresponding labels\n",
    "    break  # Just to test the first batch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding the Output\n",
    "Image Batch Shape\n",
    "\n",
    "python\n",
    "Copy code\n",
    "torch.Size([32, 3, 96, 96])\n",
    "[32, 3, 96, 96]:\n",
    "32: This is the batch size, indicating that 32 images are being processed at once.\n",
    "3: This represents the number of color channels (Red, Green, Blue) in each image.\n",
    "96, 96: These are the height and width of the images, resized to 96x96 pixels as specified in your transformation pipeline.\n",
    "This output confirms that the data loader is correctly batching and transforming your image data.\n",
    "\n",
    "Labels Tensor\n",
    "\n",
    "python\n",
    "Copy code\n",
    "tensor([1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 1])\n",
    "This tensor contains the labels for each image in the batch.\n",
    "0 and 1 are binary labels, where 1 might represent the presence of cancerous cells and 0 might represent non-cancerous cells.\n",
    "The tensor length is 32, matching the batch size, ensuring that each image has a corresponding label.\n",
    "Verifying the Dataset Class\n",
    "Your dataset class and data loader are functioning correctly, as evidenced by the output. This means:\n",
    "\n",
    "Data Loading: Images and labels are loaded correctly from their respective paths and CSV files.\n",
    "Transformations: The transformations, such as resizing and normalizing the images, are being applied properly.\n",
    "Batching: The data loader is batching images and labels together as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize a batch of images and labels\n",
    "def show_images(images, labels, n=5):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(1, n, i+1)\n",
    "        img = images[i].permute(1, 2, 0).numpy()  # Convert tensor to numpy array and permute dimensions for display\n",
    "        img = img * 0.229 + 0.485  # Unnormalize if needed (adjust this based on your normalization)\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Label: {labels[i].item()}')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Display the first 5 images and labels from the batch\n",
    "for images, labels in train_loader:\n",
    "    show_images(images, labels, n=5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation of the Visualization Code\n",
    "permute(1, 2, 0): Changes the order of dimensions from [C, H, W] to [H, W, C] for correct visualization with matplotlib.\n",
    "Unnormalize: If you normalized the images using mean and standard deviation, you may want to reverse this normalization for visualization purposes.\n",
    "Loop and Plot: Loops through the first few images and plots them with their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
